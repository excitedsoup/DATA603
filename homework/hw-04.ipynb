{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "306edecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType, StructType, StringType, TimestampType, StructField, IntegerType\n",
    "from pyspark.sql.functions import UserDefinedFunction, col, when, to_timestamp, to_utc_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58457818",
   "metadata": {},
   "source": [
    "1. Specify the schema for the crime data set. (https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15f3c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_schema = StructType([\n",
    "    StructField('X', FloatType()),\n",
    "    StructField('Y', FloatType()),\n",
    "    StructField('RowID', IntegerType()),\n",
    "    StructField('CrimeDateTime', StringType()),\n",
    "    StructField('CrimeCode', StringType()),\n",
    "    StructField('Location', StringType()),\n",
    "    StructField('Description', StringType()),\n",
    "    StructField('Inside_Outside', StringType()),\n",
    "    StructField('Weapon', StringType()),\n",
    "    StructField('Post', StringType()),\n",
    "    StructField('District', StringType()),\n",
    "    StructField('Neighborhood', StringType()),\n",
    "    StructField('Latitude', FloatType()),\n",
    "    StructField('Longitude', FloatType()),\n",
    "    StructField('Geolocation', FloatType()),\n",
    "    StructField('Premise', StringType()),\n",
    "    StructField('VRIName', StringType()),\n",
    "    StructField('Total_Incidents', StringType())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590652d",
   "metadata": {},
   "source": [
    "2. Read the file using the schema definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acacc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.options(header = 'True').schema(crime_schema).csv('Part1_Crime_data.csv')\n",
    "name = 'CrimeDateTime'\n",
    "udf = UserDefinedFunction(lambda x: x[:-3].replace('/', '-'), StringType())\n",
    "#df1 = df.select(*[udf(column).alias(name) if column == name else column for column in df.columns])\n",
    "# I'd like to do this, but I get this error:\n",
    "# Python in worker has different version 3.9 than that in driver 3.8, PySpark cannot run with different minor versions.\n",
    "# Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
    "# When I fix that, it doesn't let me change the variable type to timestamp (attempting the solutions here: https://sparkbyexamples.com/pyspark/pyspark-cast-column-type/)\n",
    "# Additionally, it makes my cached dataframe throw another error:\n",
    "#An error occurred while calling o2171.count.\n",
    "#: org.apache.spark.SparkException: Job aborted due to stage failure: Task 10 in stage 73.0 failed 1 times, most recent failure: Lost task 10.0 in stage 73.0 (TID 314) (DESKTOP-DVH32FF executor driver): java.net.SocketException: Connection reset\n",
    "# I'm not really sure where to go from here, everything else works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0846102",
   "metadata": {},
   "source": [
    "3. Cache the DataFrame (https://sparkbyexamples.com/spark/spark-dataframe-cache-and-persist-explained/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d206f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec822db3",
   "metadata": {},
   "source": [
    "4. Show the count of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0961ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5756b5",
   "metadata": {},
   "source": [
    "5. Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fd22dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- X: float (nullable = true)\n",
      " |-- Y: float (nullable = true)\n",
      " |-- RowID: integer (nullable = true)\n",
      " |-- CrimeDateTime: string (nullable = true)\n",
      " |-- CrimeCode: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Inside_Outside: string (nullable = true)\n",
      " |-- Weapon: string (nullable = true)\n",
      " |-- Post: string (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Latitude: float (nullable = true)\n",
      " |-- Longitude: float (nullable = true)\n",
      " |-- Geolocation: float (nullable = true)\n",
      " |-- Premise: string (nullable = true)\n",
      " |-- VRIName: string (nullable = true)\n",
      " |-- Total_Incidents: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172af55",
   "metadata": {},
   "source": [
    "6. Display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c799b077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+--------------------+---------+--------------------+-----------------+--------------+------+----+---------+--------------+--------+---------+-----------+-------+-------+---------------+\n",
      "|        X|        Y|RowID|       CrimeDateTime|CrimeCode|            Location|      Description|Inside_Outside|Weapon|Post| District|  Neighborhood|Latitude|Longitude|Geolocation|Premise|VRIName|Total_Incidents|\n",
      "+---------+---------+-----+--------------------+---------+--------------------+-----------------+--------------+------+----+---------+--------------+--------+---------+-----------+-------+-------+---------------+\n",
      "|1421661.4| 593584.5|    1|2021/09/24 08:00:...|       6D|500 SAINT PAUL ST...|LARCENY FROM AUTO|          null|    NA| 124|  CENTRAL|  MOUNT VERNON| 39.2959| -76.6137|       null|   null|   null|              1|\n",
      "|1428629.5|592267.25|    2|2021/09/23 02:00:...|       6D|   0 N WASHINGTON ST|LARCENY FROM AUTO|          null|    NA| 212|SOUTHEAST|BUTCHER'S HILL| 39.2922| -76.5891|       null|   null|   null|              1|\n",
      "|1429981.6| 593693.9|    3|2021/09/23 09:00:...|       6J|   400 N BRADFORD ST|          LARCENY|          null|    NA| 221|SOUTHEAST|MCELDERRY PARK| 39.2961| -76.5843|       null|   null|   null|              1|\n",
      "|1433589.5| 590796.7|    4|2021/09/23 18:27:...|       6J|      300 S EAST AVE|          LARCENY|          null|    NA| 225|SOUTHEAST|  HIGHLANDTOWN| 39.2881| -76.5716|       null|   null|   null|              1|\n",
      "|1421304.2| 591033.3|    5|2021/09/23 23:00:...|       6D|      0 S CHARLES ST|LARCENY FROM AUTO|          null|    NA| 114|  CENTRAL|      DOWNTOWN| 39.2889|  -76.615|       null|   null|   null|              1|\n",
      "+---------+---------+-----+--------------------+---------+--------------------+-----------------+--------------+------+----+---------+--------------+--------+---------+-----------+-------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6f09e",
   "metadata": {},
   "source": [
    "1. What are distinct crime codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07e178d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|CrimeCode|\n",
      "+---------+\n",
      "|       3P|\n",
      "|       3K|\n",
      "|      3BJ|\n",
      "|       1A|\n",
      "|       3M|\n",
      "|       5F|\n",
      "|       4B|\n",
      "|       3B|\n",
      "|       7A|\n",
      "|      3NF|\n",
      "|      3EF|\n",
      "|       5D|\n",
      "|       3N|\n",
      "|       6K|\n",
      "|      3LO|\n",
      "|      3AF|\n",
      "|       7B|\n",
      "|      3GO|\n",
      "|     3AJF|\n",
      "|      8GV|\n",
      "|      8AO|\n",
      "|       7C|\n",
      "|      3AK|\n",
      "|       6L|\n",
      "|      3GK|\n",
      "|      3EO|\n",
      "|      3JO|\n",
      "|       3F|\n",
      "|       1K|\n",
      "|       8H|\n",
      "|      8CV|\n",
      "|      8DO|\n",
      "|       4C|\n",
      "|       5A|\n",
      "|       6C|\n",
      "|       3D|\n",
      "|      3NK|\n",
      "|       6H|\n",
      "|      3LK|\n",
      "|     3AJK|\n",
      "|      3CO|\n",
      "|       3L|\n",
      "|       4E|\n",
      "|      8BV|\n",
      "|       6D|\n",
      "|       2A|\n",
      "|       3C|\n",
      "|       8I|\n",
      "|      3NO|\n",
      "|      3JF|\n",
      "|      3LF|\n",
      "|       3E|\n",
      "|       8J|\n",
      "|       1O|\n",
      "|      8BO|\n",
      "|      3CK|\n",
      "|       2B|\n",
      "|      3JK|\n",
      "|       5B|\n",
      "|       4A|\n",
      "|      8GO|\n",
      "|      8EV|\n",
      "|      3CF|\n",
      "|      8EO|\n",
      "|       6G|\n",
      "|       6A|\n",
      "|       9S|\n",
      "|      3EK|\n",
      "|      8FV|\n",
      "|      3GF|\n",
      "|      8CO|\n",
      "|       3G|\n",
      "|       3H|\n",
      "|       4D|\n",
      "|      8FO|\n",
      "|       6J|\n",
      "|       6F|\n",
      "|       6E|\n",
      "|       3J|\n",
      "|       5C|\n",
      "|       5G|\n",
      "|      8AV|\n",
      "|       5E|\n",
      "|     3AJO|\n",
      "|      3AO|\n",
      "|       6B|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('crime_codes')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT CrimeCode\n",
    "FROM crime_codes\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac0694",
   "metadata": {},
   "source": [
    "2. Count the number of crimes by the crime codes and order by the resulting counts in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cfd8df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|CrimeCode|count|\n",
      "+---------+-----+\n",
      "|       4E|60450|\n",
      "|       6D|45203|\n",
      "|       7A|29006|\n",
      "|       5A|28377|\n",
      "|       6J|19500|\n",
      "|       6G|17326|\n",
      "|       6E|17262|\n",
      "|       6C|16543|\n",
      "|       4C|16106|\n",
      "|      3AF|11195|\n",
      "|       5D|10804|\n",
      "|       4A|10220|\n",
      "|       4B| 9302|\n",
      "|       3B| 7712|\n",
      "|       4D| 4938|\n",
      "|       9S| 4680|\n",
      "|       5B| 4154|\n",
      "|      3CF| 2803|\n",
      "|       5C| 2787|\n",
      "|       6F| 2645|\n",
      "|     3AJF| 2419|\n",
      "|       2A| 2293|\n",
      "|      3AK| 2160|\n",
      "|       6B| 2145|\n",
      "|       3K| 1997|\n",
      "|       1A| 1969|\n",
      "|      3AO| 1772|\n",
      "|       7C| 1639|\n",
      "|       5F| 1240|\n",
      "|       3D| 1096|\n",
      "|      3JF| 1088|\n",
      "|       5E| 1007|\n",
      "|       6L|  988|\n",
      "|       8H|  668|\n",
      "|      3BJ|  598|\n",
      "|       6A|  523|\n",
      "|       3P|  503|\n",
      "|      3CK|  478|\n",
      "|      3GF|  461|\n",
      "|      3CO|  423|\n",
      "|      3JO|  351|\n",
      "|      3JK|  307|\n",
      "|      3NF|  256|\n",
      "|      8AO|  243|\n",
      "|       3H|  209|\n",
      "|       2B|  198|\n",
      "|       8J|  186|\n",
      "|     3AJO|  173|\n",
      "|       7B|  143|\n",
      "|       1K|  143|\n",
      "|       6H|  135|\n",
      "|       1O|  132|\n",
      "|      3EF|  126|\n",
      "|     3AJK|  125|\n",
      "|       3F|  102|\n",
      "|       3M|   96|\n",
      "|      3GO|   94|\n",
      "|      3GK|   93|\n",
      "|      8FO|   80|\n",
      "|      8AV|   79|\n",
      "|      3LF|   76|\n",
      "|      3NK|   66|\n",
      "|      8BO|   58|\n",
      "|      3NO|   56|\n",
      "|      8EO|   52|\n",
      "|      3EO|   35|\n",
      "|      3EK|   26|\n",
      "|      3LO|   25|\n",
      "|      8BV|   20|\n",
      "|       5G|   18|\n",
      "|      8GO|   17|\n",
      "|       3J|   14|\n",
      "|       3N|   14|\n",
      "|       8I|   12|\n",
      "|      8CO|    8|\n",
      "|      8EV|    8|\n",
      "|      8FV|    6|\n",
      "|       6K|    6|\n",
      "|       3C|    5|\n",
      "|      3LK|    5|\n",
      "|      8GV|    5|\n",
      "|      8CV|    4|\n",
      "|      8DO|    2|\n",
      "|       3L|    2|\n",
      "|       3G|    2|\n",
      "|       3E|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('crime_code_count')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT CrimeCode, COUNT(*) as count\n",
    "FROM crime_code_count\n",
    "GROUP BY CrimeCode\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e47d65",
   "metadata": {},
   "source": [
    "3. Which neighborhood had most crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce2fee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|Neighborhood           |count|\n",
      "+-----------------------+-----+\n",
      "|DUNDALK MARINE TERMINAL|5    |\n",
      "+-----------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('nb_most_crimes')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Neighborhood, COUNT(*) as count\n",
    "FROM nb_most_crimes\n",
    "GROUP BY Neighborhood\n",
    "ORDER BY count\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c4910",
   "metadata": {},
   "source": [
    "4. Which month of the year had most crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09664e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|m   |count |\n",
      "+----+------+\n",
      "|null|350294|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('most_crimes')\n",
    "\n",
    "# I presume this would work if my other part was doing what I wanted it to do, but I haven't been able to change the data type\n",
    "# or change the format without it messing up the rest of the program\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT MONTH(CrimeDateTime) as m, COUNT(*) as count\n",
    "FROM most_crimes\n",
    "GROUP BY m\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(12, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d64b1e2",
   "metadata": {},
   "source": [
    "5. What weapons were used? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73fed499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Weapon |\n",
      "+-------+\n",
      "|HANDS  |\n",
      "|KNIFE  |\n",
      "|OTHER  |\n",
      "|FIRE   |\n",
      "|FIREARM|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('weapons_used')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Weapon\n",
    "FROM weapons_used\n",
    "WHERE Weapon is not null and Weapon != 'NA'\n",
    "GROUP BY Weapon\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6be303",
   "metadata": {},
   "source": [
    "6. Which weapon was used the most? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db09d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Weapon |count|\n",
      "+-------+-----+\n",
      "|FIREARM|35293|\n",
      "+-------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView('most_used_weapon')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Weapon, COUNT(*) as count\n",
    "FROM most_used_weapon\n",
    "WHERE Weapon is not null and Weapon != 'NA'\n",
    "GROUP BY Weapon\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "output = spark.sql(query)\n",
    "output.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6af91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
